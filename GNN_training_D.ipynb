{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for training and predictions of the dispersive (D) HSP component. GNN's are more computationaly intensive, and since we test multiple models, splitting the tasks for each solubility parameter in seperate notebooks can make the outlining code more readable.\n",
    "\n",
    "The code is the same for hydrogen (H) and polar (P) components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from deepchem.models import GATModel, GCNModel, AttentiveFPModel, MPNNModel\n",
    "from deepchem.models.optimizers import Adam\n",
    "\n",
    "# Set the seed\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>al</th>\n",
       "      <th>CAS</th>\n",
       "      <th>smiles</th>\n",
       "      <th>δD</th>\n",
       "      <th>δP</th>\n",
       "      <th>δH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,1,1,2-Tetrachloroethane</td>\n",
       "      <td>b'630-20-6'</td>\n",
       "      <td>ClCC(Cl)(Cl)Cl</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,1,1-Trichloroethane</td>\n",
       "      <td>b'71-55-6'</td>\n",
       "      <td>CC(Cl)(Cl)Cl</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,1,1-Trifluoroethane</td>\n",
       "      <td>b'420-46-2'</td>\n",
       "      <td>CC(F)(F)F</td>\n",
       "      <td>14.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,1,2,2-Tetrabromoethane</td>\n",
       "      <td>b'79-27-6'</td>\n",
       "      <td>BrC(Br)C(Br)Br</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,1,2,2-Tetrachloroethane</td>\n",
       "      <td>b'79-34-5'</td>\n",
       "      <td>ClC(Cl)C(Cl)Cl</td>\n",
       "      <td>18.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>Quinine</td>\n",
       "      <td>b'130-95-0'</td>\n",
       "      <td>[H][C@@]1([C@@H](C2=CC=NC3=CC=C(C=C23)OC)O)C[C...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Sulfur Dioxide</td>\n",
       "      <td>b'9/5/7446'</td>\n",
       "      <td>O=S=O</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Thionyl Chloride</td>\n",
       "      <td>b'9/7/7719'</td>\n",
       "      <td>O=S(Cl)Cl</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Triethylene Glycol Monooleyl Ether</td>\n",
       "      <td>b'5274-66-8'</td>\n",
       "      <td>COCCOCCOCCO</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Vinyl Silane</td>\n",
       "      <td>b'7291-09-0'</td>\n",
       "      <td>C=C[SiH3]</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      al           CAS   \n",
       "0              1,1,1,2-Tetrachloroethane   b'630-20-6'  \\\n",
       "1                  1,1,1-Trichloroethane    b'71-55-6'   \n",
       "2                  1,1,1-Trifluoroethane   b'420-46-2'   \n",
       "3               1,1,2,2-Tetrabromoethane    b'79-27-6'   \n",
       "4              1,1,2,2-Tetrachloroethane    b'79-34-5'   \n",
       "...                                  ...           ...   \n",
       "1195                             Quinine   b'130-95-0'   \n",
       "1196                      Sulfur Dioxide   b'9/5/7446'   \n",
       "1197                    Thionyl Chloride   b'9/7/7719'   \n",
       "1198  Triethylene Glycol Monooleyl Ether  b'5274-66-8'   \n",
       "1199                        Vinyl Silane  b'7291-09-0'   \n",
       "\n",
       "                                                 smiles    δD    δP    δH  \n",
       "0                                        ClCC(Cl)(Cl)Cl  18.0   4.4   4.2  \n",
       "1                                          CC(Cl)(Cl)Cl  16.8   4.3   2.0  \n",
       "2                                             CC(F)(F)F  14.6  10.0   0.0  \n",
       "3                                        BrC(Br)C(Br)Br  21.0   7.0   8.2  \n",
       "4                                        ClC(Cl)C(Cl)Cl  18.8   5.1   5.3  \n",
       "...                                                 ...   ...   ...   ...  \n",
       "1195  [H][C@@]1([C@@H](C2=CC=NC3=CC=C(C=C23)OC)O)C[C...  19.0   6.6  11.0  \n",
       "1196                                              O=S=O  15.8   8.4  10.0  \n",
       "1197                                          O=S(Cl)Cl  16.9   6.4   6.1  \n",
       "1198                                        COCCOCCOCCO  16.0   3.1   8.4  \n",
       "1199                                          C=C[SiH3]  15.5   2.6   4.0  \n",
       "\n",
       "[1192 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/HSP_SMILES.csv',index_col=[0] )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the SMILES in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles=dataset['smiles'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizer - SMILES to graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the featurizer and generate molecules from SMILES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True) #featurizer with both node and edge atributes\n",
    "out = featurizer.featurize(smiles) # molecules from smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each molecule is now represented as a graph, so the task of predicting the solubility parameter is considered as a graph classification task, so we just need to define the targets (the true values of solubility parameters) similarly as for the XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=dataset.iloc[:,-3:].to_numpy() # HSP parameters : D, P, H\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the graph dataset\n",
    "\n",
    "Dispersive parameter is the first column of `targets` (`targets[:,0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_dataset = dc.data.NumpyDataset(X=out, y=np.array(targets[:,0].reshape(dataset_length,1))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "D_train_dataset, D_test_dataset = splitter.train_test_split(dataset=D_dataset, frac_train=0.8,seed=0)\n",
    "\n",
    "# Cross validation splits:\n",
    "kfold=dc.splits.RandomSplitter()\n",
    "k=5\n",
    "D_kfold=kfold.k_fold_split(dataset=D_train_dataset,k=k,seed=seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0005\n",
    "\n",
    "gat_search_space =  {\n",
    "        'layer_sizes': hp.choice('layer_sizes',[[16], [32], [16,16],[32,32],[64,64], [16,16,16],[32,32,32],[64,64,64]]),\n",
    "        'dropouts': hp.uniform('dropout',low=0.2, high=0.5)\n",
    "        }\n",
    "\n",
    "gcn_search_space = {\n",
    "        'layer_sizes': hp.choice('layer_sizes',[[16], [32], [16,16],[32,32],[64,64], [16,16,16],[32,32,32],[64,64,64]]),\n",
    "        'dropouts': hp.uniform('dropout',low=0.2, high=0.5),\n",
    "        'residual': hp.choice('residual', [True, False])\n",
    "        }\n",
    "\n",
    "att_search_space = {\n",
    "    'dropouts': hp.uniform('dropout',low=0.2, high=0.5),\n",
    "    'num_layers': hp.choice('num_layers',[1,2,3,4]),\n",
    "    'graph_feat_size':hp.choice('graph_feat_size',[50,100,200,300]),\n",
    "    'num_timesteps': hp.choice('num_timesteps',[2,4,6]) }\n",
    "\n",
    "mpnn_search_space =  {\n",
    "        'node_out_feats': hp.choice('node_out_feats',[16,32,64]),\n",
    "        'edge_hidden_feats': hp.choice('edge_hidden_feats',[16,32,64,128]),\n",
    "        'num_step_message_passing' : hp.choice('num_step_message_passing',[1,2,3,4]),\n",
    "        'dropouts': hp.uniform('dropout',low=0.2, high=0.5),\n",
    "        'self_loop':hp.choice('self_loop',[True,False])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile #tempfile is used to save the best checkpoint later in the program.\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "n_epochs = 200\n",
    "max_evals = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_scores = {'GAT':[],'GCN':[],'AttentiveFP':[],'MPNN':[]}\n",
    "#best_models = {'GAT':0,'GCN':0,'AttentiveFP':0,'MPNN':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for model selection (cross validation + hyperopt)\n",
    "\n",
    "Warning: This can take a while, depending on hardware, but it can take more than 12 hours. You can reduce the number of epochs or `max_evals`, but make sure that the model loss is stabilized or begining to stabilize when you choose the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=1\n",
    "for train,test in D_kfold:\n",
    "    print (\"Training fold: \",i)\n",
    "\n",
    "    \n",
    "    def GAT(args):\n",
    "        save_dir = tempfile.mkdtemp()\n",
    "        model = GATModel(n_tasks=1,\n",
    "                            graph_attention_layers=args['layer_sizes'],\n",
    "                            dropout=args['dropouts'],\n",
    "                            optimizer=Adam(learning_rate=lr),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            \n",
    "        #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
    "        validation=dc.models.ValidationCallback(test, 100, [metric],save_dir=save_dir,save_on_minimum=False)\n",
    "        \n",
    "        model.fit(train, nb_epoch=n_epochs,callbacks=validation)\n",
    "\n",
    "        #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
    "        model.restore(model_dir=save_dir)\n",
    "        valid_score = model.evaluate(test, [metric])\n",
    "\n",
    "        return -valid_score['r2_score']\n",
    "\n",
    "    def GCN(args):\n",
    "        save_dir = tempfile.mkdtemp()\n",
    "        model = GCNModel(n_tasks=1,graph_convolution_layers=args['layer_sizes'],dropout=args['dropouts'],\n",
    "                            residual=args['residual'],\n",
    "                            optimizer=Adam(learning_rate=lr),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
    "        validation=dc.models.ValidationCallback(test, 100, [metric],save_dir=save_dir,save_on_minimum=False)\n",
    "        \n",
    "        model.fit(train, nb_epoch=n_epochs,callbacks=validation)\n",
    "\n",
    "        #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
    "        model.restore(model_dir=save_dir)\n",
    "        valid_score = model.evaluate(test, [metric])\n",
    "\n",
    "        return -valid_score['r2_score']\n",
    "    \n",
    "    def AttentiveFP(args):\n",
    "        save_dir = tempfile.mkdtemp()\n",
    "        model = AttentiveFPModel(n_tasks=1,num_layers=args['num_layers'],\n",
    "                                    graph_feat_size=args['graph_feat_size'],\n",
    "                                    dropout=args['dropouts'], num_timesteps=args['num_timesteps'],\n",
    "                        optimizer=Adam(learning_rate=lr),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            \n",
    "        #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
    "        validation=dc.models.ValidationCallback(test, 100, [metric],save_dir=save_dir,save_on_minimum=False)\n",
    "        \n",
    "        model.fit(train, nb_epoch=n_epochs,callbacks=validation)\n",
    "\n",
    "        #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
    "        model.restore(model_dir=save_dir)\n",
    "        valid_score = model.evaluate(test, [metric])\n",
    "\n",
    "        return -valid_score['r2_score']\n",
    "    \n",
    "    def MPNN(args):\n",
    "        save_dir = tempfile.mkdtemp()\n",
    "        model = MPNNModel(n_tasks=1,\n",
    "                            node_out_feats=args['node_out_feats'],\n",
    "                            edge_hidden_feats=args['edge_hidden_feats'],\n",
    "                            num_step_message_passing = args['num_step_message_passing'],\n",
    "                            self_loop=args['self_loop'],                     \n",
    "                            dropout=args['dropouts'],\n",
    "                            optimizer=Adam(learning_rate=lr),device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "        \n",
    "    print(\"-- GAT TRAINING BEGINS --\")\n",
    "    \n",
    "    trialsGAT=Trials()\n",
    "    bestGAT = fmin(GAT,\n",
    "                space= gat_search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials = trialsGAT, rstate=np.random.default_rng(seed_value))\n",
    "    \n",
    "    \n",
    "    print(\"-- GCN TRAINING BEGINS --\")\n",
    "    \n",
    "    trialsGCN=Trials()\n",
    "    bestGCN = fmin(GCN,\n",
    "                space= gcn_search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials = trialsGCN, rstate=np.random.default_rng(seed_value))\n",
    "    \n",
    "    \n",
    "    print(\"-- ATTENTIVEFP TRAINING BEGINS --\")\n",
    "    \n",
    "    trialsAtt=Trials()\n",
    "    bestAtt = fmin(AttentiveFP,\n",
    "                space= att_search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials = trialsAtt, rstate=np.random.default_rng(seed_value))\n",
    "    \n",
    "    print(\"-- MPNN TRAINING BEGINS --\")\n",
    "\n",
    "    trialsMPNN=Trials()\n",
    "    bestMPNN = fmin(MPNN,\n",
    "                space= mpnn_search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials = trialsMPNN, rstate=np.random.default_rng(seed_value))\n",
    "    \n",
    "    CV_scores['GAT'].append(trialsGAT.trials[0]['result']['loss'])\n",
    "    CV_scores['GCN'].append(trialsGCN.trials[0]['result']['loss'])\n",
    "    CV_scores['AttentiveFP'].append(trialsAtt.trials[0]['result']['loss'])\n",
    "    CV_scores['MPNN'].append(trialsMPNN.trials[0]['result']['loss'])\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the CV results for each model and fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "out_folder =  \"results/gnn/D/\"\n",
    "name = out_folder+f'CV_D_{n_epochs}_{max_evals}.pickle'\n",
    "# Store data\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(CV_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the mean performance of models to choose which one to choose for further and final training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in CV_scores.keys():\n",
    "    print (f\"----- {key} model -----\")\n",
    "    print(f\"{key} model mean r2 scores accros folds: {np.mean(CV_scores[key])}\")\n",
    "    print(f\"{key} model standard deviation of r2 scores accros folds: {np.std(CV_scores[key])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a model with the highest mean score, but if two models have similar performance we choose the one with the smallest standard deviation. For D and H these models are AttentiveFP, while for the P parameter the model that yields slightly better results is GAT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best model hyperparameters\n",
    "\n",
    "Train the model with hyperopt and get the best model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "n_epochs = 500 \n",
    "max_evals = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data to train and validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train_dataset,D_validation_dataset, D_test_dataset = splitter.train_valid_test_split(dataset=D_dataset, frac_train=0.6,frac_valid=0.2,frac_test=0.2,seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ATT(args):\n",
    "    save_dir = tempfile.mkdtemp()\n",
    "    model = AttentiveFPModel(n_tasks=1,num_layers=args['num_layers'],\n",
    "                             graph_feat_size=args['graph_feat_size'],\n",
    "                             dropout=args['dropouts'], num_timesteps=args['num_timesteps'],\n",
    "                optimizer=Adam(learning_rate=args['learning_rate']))\n",
    "    #validation callback that saves the best checkpoint, i.e the one with the maximum score.\n",
    "    validation=dc.models.ValidationCallback(D_validation_dataset, 50, [metric],save_dir=save_dir,save_on_minimum=False)\n",
    "\n",
    "    model.fit(D_train_dataset, nb_epoch=n_epochs,callbacks=validation)\n",
    "\n",
    "    #restoring the best checkpoint and passing the negative of its validation score to be minimized.\n",
    "    model.restore(model_dir=save_dir)\n",
    "    valid_score = model.evaluate(D_validation_dataset, [metric])\n",
    "\n",
    "    return -valid_score['r2_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=Trials()\n",
    "best = fmin(ATT,\n",
    "            space= att_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=max_evals,\n",
    "            trials = trials, rstate=np.random.default_rng(seed_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the .choice arguments from the search space in lists because \"best\" returns the index of such lists and not the value itself\n",
    "layers=[1,2,3,4] \n",
    "num_layers=[1,2,3,4]\n",
    "graph_feat_size=[50,100,200,300]\n",
    "num_timesteps=[2,4,6,8]\n",
    "\n",
    "best_params = {'dropout':best['dropout'],\n",
    "               'learning_rate':best['learning_rate'],\n",
    "               'num_layers':num_layers[best['num_layers']],\n",
    "               'graph_feat_size':graph_feat_size[best['graph_feat_size']],\n",
    "               'num_timesteps':num_timesteps[best['num_timesteps']]\n",
    "              }\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, save the `best_params` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/results/gnn/D/ATT_D_params_{n_epochs}_{max_evals}.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(best_params['learning_rate'])\n",
    "\n",
    "#initialize and save the model\n",
    "model = AttentiveFPModel(n_tasks=1,**best_params,optimizer=optimizer,model_dir ='/trained_models/gnn/D/' )\n",
    "metric1 = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "metric2 = dc.metrics.Metric(dc.metrics.mean_squared_error)\n",
    "callback=dc.models.ValidationCallback(D_validation_dataset, 50, [metric1,metric2])\n",
    "model.fit(D_train_dataset, nb_epoch=n_epochs, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = model.predict(D_dataset)\n",
    "y_test = model.predict(D_test_dataset)\n",
    "\n",
    "train_val= dc.data.NumpyDataset.merge([D_train_dataset,D_validation_dataset])\n",
    "y_train_val = model.predict(train_val)\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "print('ALL r2: ', r2_score(D_dataset.y, y_all))\n",
    "print('test r2: ', r2_score(D_test_dataset.y, y_test))\n",
    "print('train-val r2: ', r2_score(train_val.y, y_train_val))\n",
    "\n",
    "print('ALL MSE: ', mean_squared_error(D_dataset.y, y_all,squared=False))\n",
    "print('test MSE: ', mean_squared_error(D_test_dataset.y, y_test,squared=False))\n",
    "print('train-val MSE: ', mean_squared_error(train_val.y, y_train_val,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"AttentiveFP\"\n",
    "TRAIN_PREDS = pd.DataFrame({'real':train_val.y.ravel(),'predicted':y_train_val.ravel()})\n",
    "TRAIN_PREDS.to_csv(f'results/gnn/D/D_TRAIN_PREDS_{model_name}_{n_epochs}_epochs.csv')\n",
    "\n",
    "TEST_PREDS = pd.DataFrame({'real':D_test_dataset.y.ravel(),'predicted':y_test.ravel()})\n",
    "TEST_PREDS.to_csv(f'results/gnn/D/D_TEST_PREDS_{model_name}_{n_epochs}_epochs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
